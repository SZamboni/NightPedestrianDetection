{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Train: 150\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Validation: 51\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/test/data/trained_models/kangaroo_cfg20191030T0853/mask_rcnn_kangaroo_cfg_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 476s 3s/step - loss: 1.4458 - rpn_class_loss: 0.0278 - rpn_bbox_loss: 0.3151 - mrcnn_class_loss: 0.1816 - mrcnn_bbox_loss: 0.4811 - mrcnn_mask_loss: 0.4402 - val_loss: 2.7247 - val_rpn_class_loss: 0.1066 - val_rpn_bbox_loss: 1.2349 - val_mrcnn_class_loss: 0.0916 - val_mrcnn_bbox_loss: 0.6703 - val_mrcnn_mask_loss: 0.6213\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "\n",
    "# split into train and test set\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "\n",
    "import os\n",
    "\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from our_dataset import OurDataset\n",
    "\n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "images_path = '/home/test/data/nightowls/validation/nightowls_validation'\n",
    "    \n",
    "# train set\n",
    "train_set = OurDataset()\n",
    "train_set.load_dataset(images_path, ann_file_path, is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "\n",
    "# val set\n",
    "val_set = OurDataset()\n",
    "val_set.load_dataset(images_path, ann_file_path, is_train=False)\n",
    "val_set.prepare()\n",
    "print('Validation: %d' % len(val_set.image_ids))\n",
    "\n",
    "'''\n",
    "k = 0\n",
    "# plot first few images\n",
    "for i in range(18,27):\n",
    "    # define subplot\n",
    "    pyplot.subplot(3,3,1+k)\n",
    "    k = k+1\n",
    "    # plot raw pixel data\n",
    "    image = train_set.load_image(i)\n",
    "    pyplot.imshow(image)\n",
    "    # plot all masks\n",
    "    mask, _ = train_set.load_mask(i)\n",
    "    for j in range(mask.shape[2]):\n",
    "        pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "        \n",
    "# show the figure\n",
    "pyplot.show()\n",
    "\n",
    "#useful debug tool:\n",
    "# enumerate all images in the dataset\n",
    "i = 0\n",
    "for image_id in train_set.image_ids:\n",
    "    if i > 9:\n",
    "        continue\n",
    "  \n",
    "    # load image info\n",
    "    info = train_set.image_info[image_id]\n",
    "    # display on the console\n",
    "    print(info)\n",
    "    i = i+1\n",
    "'''\n",
    "\n",
    "'''\n",
    "# print all the images with the masks in the dataset\n",
    "for i in range(len(train_set.image_ids)):\n",
    "    # define image id\n",
    "    image_id = i\n",
    "    # load the image\n",
    "    image = train_set.load_image(image_id)\n",
    "    # load the masks and the class ids\n",
    "    mask, class_ids = train_set.load_mask(image_id)\n",
    "    # extract bounding boxes from the masks\n",
    "    bbox = extract_bboxes(mask)\n",
    "    # display image with masks and bounding boxes\n",
    "    display_instances(image, bbox, mask, class_ids, train_set.class_names)\n",
    "'''\n",
    "\n",
    "from Mask_RCNN.mrcnn.config import Config\n",
    "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
    "\n",
    "\n",
    "# define a configuration for the model\n",
    "class TrainConfig(Config):\n",
    "\t# Give the configuration a recognizable name\n",
    "\tNAME = \"kangaroo_cfg\"\n",
    "\t# Number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 3 +1\n",
    "\t# Number of training steps per epoch\n",
    "\tSTEPS_PER_EPOCH = 150\n",
    "\n",
    "# prepare config\n",
    "config = TrainConfig()\n",
    "\n",
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='/home/test/data/trained_models/', config=config)\n",
    "\n",
    "# load weights (mscoco)\n",
    "model.load_weights('/home/test/data/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, val_set, learning_rate=config.LEARNING_RATE, epochs=1, layers='heads')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual images and predicted images\n",
    "\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "\n",
    "import os\n",
    "\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "from our_dataset import OurDataset\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = \"kangaroo_cfg\"\n",
    "    # number of classes (background + kangaroo)\n",
    "    NUM_CLASSES = 3 +1\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "images_path = '/home/test/data/nightowls/validation/nightowls_validation'\n",
    "    \n",
    "# train set\n",
    "train_set = OurDataset()\n",
    "train_set.load_dataset(images_path, ann_file_path, is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "\n",
    "# val set\n",
    "val_set = OurDataset()\n",
    "val_set.load_dataset(images_path, ann_file_path, is_train=False)\n",
    "val_set.prepare()\n",
    "print('Validation: %d' % len(val_set.image_ids))\n",
    "    \n",
    "    \n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "\n",
    "# load model weights\n",
    "model.load_weights('./trained_model/kangaroo_cfg20191028T1042/mask_rcnn_kangaroo_cfg_0001.h5', by_name=True)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# plot a number of photos with ground truth and predictions\n",
    "def plot_actual_vs_predicted(dataset, model, cfg, n_images=1):\n",
    "    # load image and mask\n",
    "    for i in range(n_images):\n",
    "        # load the image and mask\n",
    "        image = dataset.load_image(i)\n",
    "        mask, _ = dataset.load_mask(i)\n",
    "        # convert pixel values (e.g. center)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)[0]\n",
    "        # define subplot\n",
    "        \n",
    "        fig = pyplot.figure(figsize=(150, 150))\n",
    "        \n",
    "        pyplot.subplot(n_images, 2, i*2+1)\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(image)\n",
    "        pyplot.title('Actual')\n",
    "        # plot masks\n",
    "        for j in range(mask.shape[2]):\n",
    "            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "        # get the context for drawing boxes\n",
    "        pyplot.subplot(n_images, 2, i*2+2)\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(image)\n",
    "        pyplot.title('Predicted')\n",
    "        ax = pyplot.gca()\n",
    "        # plot each box\n",
    "        for box in yhat['rois']:\n",
    "            # get coordinates\n",
    "            y1, x1, y2, x2 = box\n",
    "            # calculate width and height of the box\n",
    "            width, height = x2 - x1, y2 - y1\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "    # show the figure\n",
    "    pyplot.show()\n",
    "    \n",
    "    \n",
    "# plot predictions for train dataset\n",
    "plot_actual_vs_predicted(train_set, model, cfg)\n",
    "# plot predictions for test dataset\n",
    "plot_actual_vs_predicted(val_set, model, cfg)\n",
    "\n",
    "'''\n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "\tAPs = list()\n",
    "\tfor image_id in dataset.image_ids:\n",
    "\t\t# load image, bounding boxes and masks for the image id\n",
    "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)\n",
    "\t\t# extract results for first sample\n",
    "\t\tr = yhat[0]\n",
    "\t\t# calculate statistics, including AP\n",
    "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\t\t# store\n",
    "\t\tAPs.append(AP)\n",
    "\t# calculate the mean AP across all images\n",
    "\tmAP = mean(APs)\n",
    "\treturn mAP\n",
    "\n",
    "# evaluate model on training dataset\n",
    "train_mAP = evaluate_model(train_set, model, cfg)\n",
    "print(\"Train mAP: %.3f\" % train_mAP)\n",
    "# evaluate model on val dataset\n",
    "test_mAP = evaluate_model(val_set, model, cfg)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Validation: 51\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Re-starting from epoch 1\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# create the file for the output\n",
    "# that file is a json containint a list of objects like this\n",
    "# {\"image_id\":7000000,\"category_id\":1,\n",
    "# \"bbox\":[645.55109817521941,229.397521973,21.598609313961,52.6795349121],\"score\":0.0935320705175}\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "\n",
    "import os\n",
    "\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "from our_dataset import OurDataset\n",
    "\n",
    "def fromOutputToAnn(image_id,out):\n",
    "    \n",
    "    recognized_objects = []\n",
    "    \n",
    "    for i in range(len(out['class_ids'])):\n",
    "        class_id = out['class_ids'][i]\n",
    "        bbox = out['rois'][i]\n",
    "        score = out['scores'][i]\n",
    "        # from [xmin, ymin, xmax, ymax] to [xmin, ymin, width, height]\n",
    "        bbox[2] = bbox[2]-bbox[0]\n",
    "        bbox[3] = bbox[3]-bbox[1]\n",
    "        \n",
    "        bbox[0] = float(bbox[0])\n",
    "        bbox[1] = float(bbox[1])\n",
    "        bbox[2] = float(bbox[2])\n",
    "        bbox[3] = float(bbox[3])\n",
    "        \n",
    "        bbox = bbox.tolist()\n",
    "        \n",
    "        \n",
    "        entry = {\n",
    "            \"category_id\": int(class_id),\n",
    "            \"bbox\" : bbox,\n",
    "            \"score\": float(score),\n",
    "            \"image_id\" : int(image_id)\n",
    "        }\n",
    "        recognized_objects.append(entry)\n",
    "        \n",
    "    return recognized_objects\n",
    "    \n",
    "\n",
    "def generateAnnotations(dataset,model):\n",
    "    i = 0\n",
    "    all_outputs = []\n",
    "    for image_id in dataset.image_ids:\n",
    "        # load image info\n",
    "        info = dataset.image_info[image_id]\n",
    "        \n",
    "        image = dataset.load_image(i)\n",
    "        mask, _ = dataset.load_mask(i)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)[0]\n",
    "        \n",
    "        out = fromOutputToAnn(info['real_id'],yhat)\n",
    "        all_outputs.extend(out)\n",
    "        \n",
    "        i = i+1\n",
    "    return all_outputs\n",
    "    \n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = \"kangaroo_cfg\"\n",
    "    # number of classes (background + kangaroo)\n",
    "    NUM_CLASSES = 3 +1\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "images_path = '/home/test/data/nightowls/validation/nightowls_validation'\n",
    "    \n",
    "# val set\n",
    "val_set = OurDataset()\n",
    "val_set.load_dataset(images_path, ann_file_path, is_train=False)\n",
    "val_set.prepare()\n",
    "print('Validation: %d' % len(val_set.image_ids))\n",
    "\n",
    "i = 0\n",
    "\n",
    "    \n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "\n",
    "# load model weights\n",
    "model.load_weights('/home/test/data/trained_models/kangaroo_cfg20191030T0853/mask_rcnn_kangaroo_cfg_0001.h5', by_name=True)\n",
    "\n",
    "json_output = generateAnnotations(val_set,model)\n",
    "#print(json_output)\n",
    "\n",
    "with open('out.json', 'w') as outfile:\n",
    "    json.dump(json_output, outfile)\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable         [ IoU=0.50      | height=[50:10000000000] | visibility=[0.65:10000000000.00] ] = 100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_small   [ IoU=0.50      | height=[50:75] | visibility=[0.65:10000000000.00] ] = 100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_occ=heavy [ IoU=0.50      | height=[50:10000000000] | visibility=[0.20:0.65] ] = 100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-689bf7fb5e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#resFile = '../sample-Faster-RCNN-nightowls_validation.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-689bf7fb5e23>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(annFile, resFile, outFile)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcocoEval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcocoGt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcocoDt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcocoEval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgIds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimgIds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcocoEval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_setup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcocoEval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcocoEval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_setup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NightPedestrianDetection/Code/maskrcnnkeras/eval_MR_multisetup.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, id_setup)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mVisRng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisRng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_setup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         self.evalImgs = [evaluateImg(imgId, catId, HtRng, VisRng, maxDet)\n\u001b[0;32m--> 150\u001b[0;31m                  \u001b[0;32mfor\u001b[0m \u001b[0mcatId\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcatIds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                  \u001b[0;32mfor\u001b[0m \u001b[0mimgId\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m              ]\n",
      "\u001b[0;32m~/NightPedestrianDetection/Code/maskrcnnkeras/eval_MR_multisetup.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    149\u001b[0m         self.evalImgs = [evaluateImg(imgId, catId, HtRng, VisRng, maxDet)\n\u001b[1;32m    150\u001b[0m                  \u001b[0;32mfor\u001b[0m \u001b[0mcatId\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcatIds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                  \u001b[0;32mfor\u001b[0m \u001b[0mimgId\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m              ]\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_paramsEval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NightPedestrianDetection/Code/maskrcnnkeras/eval_MR_multisetup.py\u001b[0m in \u001b[0;36mevaluateImg\u001b[0;34m(self, imgId, catId, hRng, vRng, maxDet)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# load computed ious\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mious\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mious\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mious\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mious\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mious\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mious\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgtind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Function that takes in input the ground truth file of the annotation \n",
    "and the output of a network in the json format and outputs the\n",
    "miss rates in the output file\n",
    "'''\n",
    "def evaluation(annFile,resFile,outFile = \"results.txt\"):\n",
    "    from coco import COCO # IMPORT THEIR COCO, not pycocotools\n",
    "    from eval_MR_multisetup import COCOeval\n",
    "    \n",
    "    # running evaluation\n",
    "    res_file = open(\"results.txt\", \"w\")\n",
    "    for id_setup in range(0,4):\n",
    "        cocoGt = COCO(annFile)\n",
    "        cocoDt = cocoGt.loadRes(resFile)\n",
    "        imgIds = sorted(cocoGt.getImgIds())\n",
    "        cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "        cocoEval.params.imgIds  = imgIds\n",
    "        cocoEval.evaluate(id_setup)\n",
    "        cocoEval.accumulate()\n",
    "        cocoEval.summarize(id_setup,res_file)\n",
    "\n",
    "    res_file.close()\n",
    "\n",
    "\n",
    "# Ground truth\n",
    "annFile = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "#annFile = '/home/test/data/nightowls/nightowls_validation.json'\n",
    "\n",
    "# Detections\n",
    "resFile = './out.json'\n",
    "#resFile = '../sample-Faster-RCNN-nightowls_validation.json'\n",
    "\n",
    "evaluation(annFile,resFile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
