{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 131\n",
      "Test: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '00125', 'source': 'dataset', 'path': 'kangaroo/images/00125.jpg', 'annotation': 'kangaroo/annots/00125.xml'}\n",
      "{'id': '00083', 'source': 'dataset', 'path': 'kangaroo/images/00083.jpg', 'annotation': 'kangaroo/annots/00083.xml'}\n",
      "{'id': '00054', 'source': 'dataset', 'path': 'kangaroo/images/00054.jpg', 'annotation': 'kangaroo/annots/00054.xml'}\n",
      "{'id': '00091', 'source': 'dataset', 'path': 'kangaroo/images/00091.jpg', 'annotation': 'kangaroo/annots/00091.xml'}\n",
      "{'id': '00140', 'source': 'dataset', 'path': 'kangaroo/images/00140.jpg', 'annotation': 'kangaroo/annots/00140.xml'}\n",
      "{'id': '00034', 'source': 'dataset', 'path': 'kangaroo/images/00034.jpg', 'annotation': 'kangaroo/annots/00034.xml'}\n",
      "{'id': '00127', 'source': 'dataset', 'path': 'kangaroo/images/00127.jpg', 'annotation': 'kangaroo/annots/00127.xml'}\n",
      "{'id': '00059', 'source': 'dataset', 'path': 'kangaroo/images/00059.jpg', 'annotation': 'kangaroo/annots/00059.xml'}\n",
      "{'id': '00005', 'source': 'dataset', 'path': 'kangaroo/images/00005.jpg', 'annotation': 'kangaroo/annots/00005.xml'}\n",
      "{'id': '00149', 'source': 'dataset', 'path': 'kangaroo/images/00149.jpg', 'annotation': 'kangaroo/annots/00149.xml'}\n",
      "{'id': '00136', 'source': 'dataset', 'path': 'kangaroo/images/00136.jpg', 'annotation': 'kangaroo/annots/00136.xml'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: ./trained_model/kangaroo_cfg20191027T1638/mask_rcnn_kangaroo_cfg_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/2\n",
      "131/131 [==============================] - 419s 3s/step - loss: 1.0173 - rpn_class_loss: 0.0075 - rpn_bbox_loss: 0.2566 - mrcnn_class_loss: 0.0348 - mrcnn_bbox_loss: 0.3902 - mrcnn_mask_loss: 0.3282 - val_loss: 0.9820 - val_rpn_class_loss: 0.0123 - val_rpn_bbox_loss: 0.3798 - val_mrcnn_class_loss: 0.0238 - val_mrcnn_bbox_loss: 0.3116 - val_mrcnn_mask_loss: 0.2545\n",
      "Epoch 2/2\n",
      "131/131 [==============================] - 336s 3s/step - loss: 0.7746 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.2459 - mrcnn_class_loss: 0.0387 - mrcnn_bbox_loss: 0.2373 - mrcnn_mask_loss: 0.2467 - val_loss: 0.8310 - val_rpn_class_loss: 0.0125 - val_rpn_bbox_loss: 0.2924 - val_mrcnn_class_loss: 0.0466 - val_mrcnn_bbox_loss: 0.2135 - val_mrcnn_mask_loss: 0.2660\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and test set\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# train set\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "\n",
    "# test/val set\n",
    "test_set = KangarooDataset()\n",
    "test_set.load_dataset('kangaroo', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# plot raw pixel data\n",
    "\timage = train_set.load_image(i)\n",
    "\tpyplot.imshow(image)\n",
    "\t# plot all masks\n",
    "\tmask, _ = train_set.load_mask(i)\n",
    "\tfor j in range(mask.shape[2]):\n",
    "\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "# show the figure\n",
    "pyplot.show()\n",
    "\n",
    "#useful debug tool:\n",
    "# enumerate all images in the dataset\n",
    "i = 0\n",
    "for image_id in train_set.image_ids:\n",
    "  if i > 10:\n",
    "    continue\n",
    "  \n",
    "\t# load image info\n",
    "  info = train_set.image_info[image_id]\n",
    "\t# display on the console\n",
    "  print(info)\n",
    "  i = i+1\n",
    "  \n",
    "# define image id\n",
    "image_id = 1\n",
    "# load the image\n",
    "image = train_set.load_image(image_id)\n",
    "# load the masks and the class ids\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "# extract bounding boxes from the masks\n",
    "bbox = extract_bboxes(mask)\n",
    "# display image with masks and bounding boxes\n",
    "display_instances(image, bbox, mask, class_ids, train_set.class_names)\n",
    "\n",
    "# to make dysplay_instances work I had to go to mrcnn.visualize and eliminate the import of utils\n",
    "\n",
    "\n",
    "from Mask_RCNN.mrcnn.config import Config\n",
    "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
    "\n",
    "\n",
    "# define a configuration for the model\n",
    "class KangarooConfig(Config):\n",
    "\t# Give the configuration a recognizable name\n",
    "\tNAME = \"kangaroo_cfg\"\n",
    "\t# Number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# Number of training steps per epoch\n",
    "\tSTEPS_PER_EPOCH = 131\n",
    "\n",
    "# prepare config\n",
    "config = KangarooConfig()\n",
    "\n",
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='./trained_model', config=config)\n",
    "\n",
    "# load weights (mscoco)\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=2, layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 131\n",
      "Test: 32\n",
      "Re-starting from epoch 2\n",
      "Train mAP: 0.850\n",
      "Test mAP: 0.921\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# class that defines and loads the kangaroo dataset\n",
    "class KangarooDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define one class\n",
    "\t\tself.add_class(\"dataset\", 1, \"kangaroo\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif image_id in ['00090']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 150 if we are building the train set\n",
    "\t\t\tif is_train and int(image_id) >= 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 150 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 150:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\tclass_ids.append(self.class_names.index('kangaroo'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# train set\n",
    "train_set = KangarooDataset()\n",
    "train_set.load_dataset('kangaroo', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "\n",
    "# test/val set\n",
    "test_set = KangarooDataset()\n",
    "test_set.load_dataset('kangaroo', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = \"kangaroo_cfg\"\n",
    "    # number of classes (background + kangaroo)\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "\n",
    "# load model weights\n",
    "model.load_weights('./trained_model/kangaroo_cfg20191027T1638/mask_rcnn_kangaroo_cfg_0002.h5', by_name=True)\n",
    "\n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "\tAPs = list()\n",
    "\tfor image_id in dataset.image_ids:\n",
    "\t\t# load image, bounding boxes and masks for the image id\n",
    "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)\n",
    "\t\t# extract results for first sample\n",
    "\t\tr = yhat[0]\n",
    "\t\t# calculate statistics, including AP\n",
    "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\t\t# store\n",
    "\t\tAPs.append(AP)\n",
    "\t# calculate the mean AP across all images\n",
    "\tmAP = mean(APs)\n",
    "\treturn mAP\n",
    "\n",
    "# evaluate model on training dataset\n",
    "train_mAP = evaluate_model(train_set, model, cfg)\n",
    "print(\"Train mAP: %.3f\" % train_mAP)\n",
    "# evaluate model on test dataset\n",
    "test_mAP = evaluate_model(test_set, model, cfg)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
