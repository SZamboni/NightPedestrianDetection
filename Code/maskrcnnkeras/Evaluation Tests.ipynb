{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR FILE\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      "THEIR FILE\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.18s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n"
     ]
    }
   ],
   "source": [
    "# OFFICIAL COCO EVALUATION\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "'''\n",
    "REAL COCO EVALUATION\n",
    "'''\n",
    "def evaluation(annFile,resFile,outFile = \"results.txt\"):\n",
    "    from pycocotools.coco import COCO\n",
    "    from pycocotools.cocoeval import COCOeval\n",
    "    \n",
    "    cocoGt=COCO(annFile)\n",
    "    cocoDt=cocoGt.loadRes(resFile)\n",
    "    imgIds=sorted(cocoGt.getImgIds())\n",
    "    cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "    cocoEval.params.imgIds  = imgIds\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    \n",
    "    \n",
    "def main(ann_file, pred_file):\n",
    "    \n",
    "     evaluation(ann_file,pred_file)\n",
    "\n",
    "print('OUR FILE')        \n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "net_predictions_file = './out.json'\n",
    "\n",
    "main(ann_file_path, net_predictions_file)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print('THEIR FILE')        \n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "net_predictions_file = './their_small_dataset.json'\n",
    "\n",
    "main(ann_file_path, net_predictions_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR FILE\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable         [ IoU=0.50      | height=[50:10000000000] | visibility=[0.65:10000000000.00] ] = 55.83%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_small   [ IoU=0.50      | height=[50:75] | visibility=[0.65:10000000000.00] ] = 63.35%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_occ=heavy [ IoU=0.50      | height=[50:10000000000] | visibility=[0.20:0.65] ] = 92.37%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ All                [ IoU=0.50      | height=[20:10000000000] | visibility=[0.20:10000000000.00] ] = 77.60%\n",
      "THEIR FILE\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable         [ IoU=0.50      | height=[50:10000000000] | visibility=[0.65:10000000000.00] ] = 53.15%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_small   [ IoU=0.50      | height=[50:75] | visibility=[0.65:10000000000.00] ] = 69.92%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_occ=heavy [ IoU=0.50      | height=[50:10000000000] | visibility=[0.20:0.65] ] = 93.31%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ All                [ IoU=0.50      | height=[20:10000000000] | visibility=[0.20:10000000000.00] ] = 79.95%\n"
     ]
    }
   ],
   "source": [
    "# NIGHTOWL EVALUATION\n",
    "\n",
    "'''\n",
    "Function that takes in input the ground truth file of the annotation \n",
    "and the output of a network in the json format and outputs the\n",
    "miss rates in the output file\n",
    "'''\n",
    "def evaluation(annFile,resFile,outFile = \"results.txt\"):\n",
    "    from coco import COCO # IMPORT THEIR COCO, not pycocotools\n",
    "    from eval_MR_multisetup import COCOeval\n",
    "    \n",
    "    # running evaluation\n",
    "    res_file = open(\"results.txt\", \"w\")\n",
    "    for id_setup in range(0,4):\n",
    "        cocoGt = COCO(annFile)\n",
    "        cocoDt = cocoGt.loadRes(resFile)\n",
    "        imgIds = sorted(cocoGt.getImgIds())\n",
    "        cocoEval = COCOeval(cocoGt,cocoDt,'bbox')\n",
    "        cocoEval.params.imgIds  = imgIds\n",
    "        cocoEval.evaluate(id_setup)\n",
    "        cocoEval.accumulate()\n",
    "        cocoEval.summarize(id_setup,res_file)\n",
    "\n",
    "    res_file.close()\n",
    "\n",
    "def main(ann_file, pred_file):\n",
    "    \n",
    "     evaluation(ann_file,pred_file)\n",
    "\n",
    "print('OUR FILE')        \n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "net_predictions_file = './out.json'\n",
    "\n",
    "main(ann_file_path, net_predictions_file)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('THEIR FILE')        \n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "net_predictions_file = './their_small_dataset.json'\n",
    "\n",
    "main(ann_file_path, net_predictions_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "from our_dataset_onlyped import OurDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def main(ann_file_path,images_dir,net_predictions_file):\n",
    "    # train set\n",
    "    train_set = OurDataset()\n",
    "    train_set.load_dataset(images_dir, ann_file_path, is_train=True, val_percentage = 0.0)\n",
    "    train_set.prepare()\n",
    "    print('Train images: %d' % len(train_set.image_ids))\n",
    "    \n",
    "    input_file = open (net_predictions_file)\n",
    "    datastore = json.load(input_file)\n",
    "    \n",
    "    for image_id in train_set.image_ids:\n",
    "        info = train_set.image_info[image_id]\n",
    "        real_id = info['real_id']\n",
    "        #print(info)\n",
    "        if image_id < 30 and image_id > 25:\n",
    "            continue\n",
    "        # load the image\n",
    "        image = train_set.load_image(image_id)\n",
    "        # load the masks and the class ids\n",
    "        mask, class_ids = train_set.load_mask(image_id)\n",
    "        # extract bounding boxes from the masks\n",
    "        bbox = extract_bboxes(mask)\n",
    "        # display image with masks and bounding boxes\n",
    "        display_instances(image, bbox, mask, class_ids, train_set.class_names)\n",
    "        \n",
    "        for i in datastore:\n",
    "            if i['image_id'] == real_id:\n",
    "                '''\n",
    "                if i['score'] < 0.0001 :\n",
    "                    continue\n",
    "                '''\n",
    "                \n",
    "                im = np.array(Image.open(info['path']), dtype=np.uint8)\n",
    "                bbox = i['bbox']\n",
    "                \n",
    "                # Create figure and axes\n",
    "                fig,ax = plt.subplots(1)\n",
    "\n",
    "                # Display the image\n",
    "                ax.imshow(im)\n",
    "\n",
    "                # Create a Rectangle patch\n",
    "                rect = patches.Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3],linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "                # Add the patch to the Axes\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "                plt.show()\n",
    "                \n",
    "        \n",
    "\n",
    "    \n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "images_path = '/home/test/data/nightowls/validation/nightowls_validation'\n",
    "net_predictions_file = './their_very_small_dataset.json'\n",
    "    \n",
    "main(ann_file_path,images_path,net_predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
