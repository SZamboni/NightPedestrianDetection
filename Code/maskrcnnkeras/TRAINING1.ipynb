{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1031 09:06:27.160897 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1031 09:06:27.184916 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1031 09:06:27.212125 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1031 09:06:27.251906 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Train images: 112\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Validation images: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 09:06:31.371671 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W1031 09:06:31.893267 140411151095168 deprecation.py:506] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1031 09:06:31.898061 140411151095168 deprecation.py:506] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1031 09:06:32.496433 140411151095168 deprecation.py:323] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1031 09:06:32.700761 140411151095168 deprecation_wrapper.py:119] From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "W1031 09:06:32.805345 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1031 09:06:32.844165 140411151095168 deprecation.py:506] From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/test/data/trained_models/pedestrian_only_traincfg20191031T0907/mask_rcnn_pedestrian_only_traincfg_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 09:07:43.292670 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "W1031 09:08:07.123941 140411151095168 deprecation.py:506] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1031 09:08:16.652314 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W1031 09:08:16.653507 140411151095168 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/training.py:2039: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "111/112 [============================>.] - ETA: 4s - loss: 0.9711 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.1648 - mrcnn_class_loss: 0.0521 - mrcnn_bbox_loss: 0.3343 - mrcnn_mask_loss: 0.4095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/training.py:2197: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 774s 7s/step - loss: 0.9664 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.1639 - mrcnn_class_loss: 0.0518 - mrcnn_bbox_loss: 0.3324 - mrcnn_mask_loss: 0.4080 - val_loss: 0.9657 - val_rpn_class_loss: 0.0039 - val_rpn_bbox_loss: 0.2053 - val_mrcnn_class_loss: 0.0084 - val_mrcnn_bbox_loss: 0.3126 - val_mrcnn_mask_loss: 0.4355\n",
      "Epoch 2/2\n",
      "112/112 [==============================] - 475s 4s/step - loss: 0.4530 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.0838 - mrcnn_class_loss: 0.0144 - mrcnn_bbox_loss: 0.1359 - mrcnn_mask_loss: 0.2154 - val_loss: 0.7820 - val_rpn_class_loss: 0.0025 - val_rpn_bbox_loss: 0.1443 - val_mrcnn_class_loss: 0.0090 - val_mrcnn_bbox_loss: 0.2470 - val_mrcnn_mask_loss: 0.3792\n",
      "Training DONE\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "import os\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from Mask_RCNN.mrcnn.config import Config\n",
    "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
    "\n",
    "from our_dataset_onlyped import OurDataset\n",
    "\n",
    "# define a configuration for the model\n",
    "class TrainConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"pedestrian_only_traincfg\"\n",
    "    # Number of classes (background + kangaroo)\n",
    "    NUM_CLASSES = 2\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 112\n",
    "    \n",
    "    LEARNING_RATE = 1e-3\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "def main(ann_file_path,images_path,learning_rate,epochs,val_percentage,model_weights):\n",
    "    # train set\n",
    "    train_set = OurDataset()\n",
    "    train_set.load_dataset(images_path, ann_file_path, is_train=True, val_percentage = val_percentage)\n",
    "    train_set.prepare()\n",
    "    print('Train images: %d' % len(train_set.image_ids))\n",
    "\n",
    "    # val set\n",
    "    val_set = OurDataset()\n",
    "    val_set.load_dataset(images_path, ann_file_path, is_train=False, val_percentage = val_percentage)\n",
    "    val_set.prepare()\n",
    "    print('Validation images: %d' % len(val_set.image_ids))\n",
    "\n",
    "    # prepare config\n",
    "    config = TrainConfig()\n",
    "\n",
    "    # define the model\n",
    "    model = MaskRCNN(mode='training', model_dir='/home/test/data/trained_models/', config=config)\n",
    "\n",
    "    # load weights (mscoco)\n",
    "    model.load_weights(model_weights, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "    # train weights (output layers or 'heads')\n",
    "    model.train(train_set, val_set, learning_rate=config.LEARNING_RATE, epochs=epochs, layers='all')\n",
    "\n",
    "    print('Training DONE')\n",
    "\n",
    "\n",
    "ann_file_path = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "images_path = '/home/test/data/nightowls/nightowls_validation'\n",
    "model_weights = '/home/test/data/mask_rcnn_coco.h5'\n",
    "learning_rate = 1e-3\n",
    "epochs = 1\n",
    "val_percentage = 0.1\n",
    "\n",
    "main(ann_file_path,images_path,learning_rate,epochs, val_percentage,model_weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1031 10:32:34.872838 140595408635264 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1031 10:32:34.925933 140595408635264 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1031 10:32:34.930710 140595408635264 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1031 10:32:34.965255 140595408635264 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Test images: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 10:32:38.809057 140595408635264 deprecation_wrapper.py:119] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W1031 10:32:39.142692 140595408635264 deprecation.py:506] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1031 10:32:39.147743 140595408635264 deprecation.py:506] From /home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W1031 10:32:39.532589 140595408635264 deprecation_wrapper.py:119] From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1031 10:32:39.544206 140595408635264 deprecation.py:323] From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1031 10:32:39.551778 140595408635264 deprecation.py:506] From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W1031 10:32:39.855240 140595408635264 deprecation_wrapper.py:119] From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "W1031 10:32:39.861355 140595408635264 deprecation_wrapper.py:119] From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "W1031 10:32:39.971784 140595408635264 deprecation.py:323] From /home/test/NightPedestrianDetection/Code/maskrcnnkeras/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 2\n",
      "RESULTS FILE GENERATED\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable         [ IoU=0.05      | height=[50:10000000000] | visibility=[0.65:10000000000.00] ] = -100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_small   [ IoU=0.05      | height=[50:75] | visibility=[0.65:10000000000.00] ] = -100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_occ=heavy [ IoU=0.05      | height=[50:10000000000] | visibility=[0.20:0.65] ] = -100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ All                [ IoU=0.05      | height=[20:10000000000] | visibility=[0.20:10000000000.00] ] = -100.00%\n",
      "EVALUATION DONE\n",
      "PROGRAM FINISHED\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "import os\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import json\n",
    "\n",
    "from Mask_RCNN.mrcnn.config import Config\n",
    "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
    "\n",
    "from our_dataset_onlyped import OurDataset\n",
    "\n",
    "from our_evaluation import generateAnnotations, evaluation\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "    \n",
    "    IMAGES_PER_GPU = 1\n",
    "    # define the name of the configuration\n",
    "    NAME = \"pedestrian_only_testcfg\"\n",
    "    # number of classes (background + kangaroo)\n",
    "    NUM_CLASSES = 2\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "def main(images_dir, ann_file, pred_file, net_weights_file):\n",
    "    \n",
    "    # test set\n",
    "    test_set = OurDataset()\n",
    "    test_set.load_dataset(images_dir, ann_file, is_train=True, val_percentage = 0.0)\n",
    "    test_set.prepare()\n",
    "    print('Test images: %d' % len(test_set.image_ids))\n",
    "    \n",
    "    # create config\n",
    "    cfg = PredictionConfig()\n",
    "\n",
    "    # define the model\n",
    "    model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "\n",
    "    # load model weights\n",
    "    model.load_weights(net_weights_file, by_name=True)\n",
    "\n",
    "    # generate the annotations for the test set using the model\n",
    "    json_output = generateAnnotations(test_set,model,cfg)\n",
    "\n",
    "    # save the file\n",
    "    with open(pred_file, 'w') as outfile:\n",
    "        json.dump(json_output, outfile)\n",
    "\n",
    "    print('RESULTS FILE GENERATED')\n",
    "    \n",
    "    # evalutate the predictions and save them in results.txt\n",
    "    evaluation(ann_file,pred_file)\n",
    "    \n",
    "    print('EVALUATION DONE')\n",
    "    \n",
    "    print('PROGRAM FINISHED')\n",
    "\n",
    "net_weights_file = '/home/test/data/trained_models/pedestrian_only_traincfg20191031T0907/mask_rcnn_pedestrian_only_traincfg_0002.h5'\n",
    "ann_file = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "images_dir = '/home/test/data/nightowls/nightowls_validation'\n",
    "net_predictions_file = './out.json'\n",
    "\n",
    "main(images_dir,ann_file, net_predictions_file, net_weights_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable         [ IoU=0.50      | height=[50:10000000000] | visibility=[0.65:10000000000.00] ] = -100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_small   [ IoU=0.50      | height=[50:75] | visibility=[0.65:10000000000.00] ] = -100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ Reasonable_occ=heavy [ IoU=0.50      | height=[50:10000000000] | visibility=[0.20:0.65] ] = -100.00%\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Miss Rate  (MR) @ All                [ IoU=0.50      | height=[20:10000000000] | visibility=[0.20:10000000000.00] ] = 0.00%\n",
      "EVALUATION DONE\n"
     ]
    }
   ],
   "source": [
    "# TO ONLY EVALUATE THE OUTPUT FILE\n",
    "\n",
    "from our_evaluation import generateAnnotations, evaluation\n",
    "\n",
    "def main(ann_file, net_predictions_file):  \n",
    "    # evalutate the predictions and save them in results.txt\n",
    "    evaluation(ann_file,net_predictions_file)\n",
    "    \n",
    "    print('EVALUATION DONE')\n",
    "    \n",
    "\n",
    "ann_file = 'nightowls_validation_small copy.json'\n",
    "net_predictions_file = './fake.json'\n",
    "\n",
    "main(ann_file, net_predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Test images: 130\n",
      "Re-starting from epoch 2\n",
      "image_id: 0\n",
      "image_id: 1\n",
      "image_id: 2\n",
      "image_id: 3\n",
      "image_id: 4\n",
      "image_id: 5\n",
      "image_id: 6\n",
      "image_id: 7\n",
      "image_id: 8\n",
      "image_id: 9\n",
      "image_id: 10\n",
      "image_id: 11\n",
      "image_id: 12\n",
      "image_id: 13\n",
      "image_id: 14\n",
      "image_id: 15\n",
      "image_id: 16\n",
      "image_id: 17\n",
      "image_id: 18\n",
      "image_id: 19\n",
      "image_id: 20\n",
      "image_id: 21\n",
      "image_id: 22\n",
      "image_id: 23\n",
      "image_id: 24\n",
      "image_id: 25\n",
      "image_id: 26\n",
      "image_id: 27\n",
      "image_id: 28\n",
      "image_id: 29\n",
      "image_id: 30\n",
      "image_id: 31\n",
      "image_id: 32\n",
      "image_id: 33\n",
      "image_id: 34\n",
      "image_id: 35\n",
      "image_id: 36\n",
      "image_id: 37\n",
      "image_id: 38\n",
      "image_id: 39\n",
      "image_id: 40\n",
      "image_id: 41\n",
      "image_id: 42\n",
      "image_id: 43\n",
      "image_id: 44\n",
      "image_id: 45\n",
      "image_id: 46\n",
      "image_id: 47\n",
      "image_id: 48\n",
      "image_id: 49\n",
      "image_id: 50\n",
      "image_id: 51\n",
      "image_id: 52\n",
      "image_id: 53\n",
      "image_id: 54\n",
      "image_id: 55\n",
      "image_id: 56\n",
      "image_id: 58\n",
      "image_id: 59\n",
      "image_id: 60\n",
      "image_id: 61\n",
      "image_id: 62\n",
      "image_id: 63\n",
      "image_id: 64\n",
      "image_id: 65\n",
      "image_id: 66\n",
      "image_id: 67\n",
      "image_id: 68\n",
      "image_id: 69\n",
      "image_id: 70\n",
      "image_id: 71\n",
      "image_id: 72\n",
      "image_id: 73\n",
      "image_id: 74\n",
      "image_id: 75\n",
      "image_id: 76\n",
      "image_id: 77\n",
      "image_id: 78\n",
      "image_id: 79\n",
      "image_id: 80\n",
      "image_id: 81\n",
      "image_id: 82\n",
      "image_id: 83\n",
      "image_id: 84\n",
      "image_id: 85\n",
      "image_id: 86\n",
      "image_id: 87\n",
      "image_id: 88\n",
      "image_id: 89\n",
      "image_id: 90\n",
      "image_id: 91\n",
      "image_id: 92\n",
      "image_id: 93\n",
      "image_id: 94\n",
      "image_id: 95\n",
      "image_id: 96\n",
      "image_id: 97\n",
      "image_id: 98\n",
      "image_id: 99\n",
      "image_id: 100\n",
      "image_id: 101\n",
      "image_id: 102\n",
      "image_id: 103\n",
      "image_id: 104\n",
      "image_id: 105\n",
      "image_id: 106\n",
      "image_id: 107\n",
      "image_id: 108\n",
      "image_id: 109\n",
      "image_id: 110\n",
      "image_id: 111\n",
      "image_id: 112\n",
      "image_id: 113\n",
      "image_id: 114\n",
      "image_id: 115\n",
      "image_id: 116\n",
      "image_id: 117\n",
      "image_id: 118\n",
      "image_id: 119\n",
      "image_id: 120\n",
      "image_id: 121\n",
      "image_id: 122\n",
      "image_id: 123\n",
      "image_id: 124\n",
      "image_id: 125\n",
      "image_id: 126\n",
      "image_id: 127\n",
      "image_id: 128\n",
      "image_id: 129\n",
      "Train mAP: 0.649\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE MaP\n",
    "\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "import os\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import json\n",
    "\n",
    "from Mask_RCNN.mrcnn.config import Config\n",
    "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
    "\n",
    "from our_dataset_onlyped import OurDataset\n",
    "\n",
    "net_weights_file = '/home/test/data/trained_models/pedestrian_only_traincfg20191031T0907/mask_rcnn_pedestrian_only_traincfg_0002.h5'\n",
    "ann_file = '/home/test/data/nightowls/nightowls_validation_small.json'\n",
    "images_dir = '/home/test/data/nightowls/nightowls_validation'\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "    \n",
    "    IMAGES_PER_GPU = 1\n",
    "    # define the name of the configuration\n",
    "    NAME = \"pedestrian_only_testcfg\"\n",
    "    # number of classes (background + kangaroo)\n",
    "    NUM_CLASSES = 2\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "    APs = list()\n",
    "    for image_id in dataset.image_ids:\n",
    "        \n",
    "        if image_id == 57:\n",
    "            continue\n",
    "        \n",
    "        print('image_id: ' + str(image_id))\n",
    "        # load image, bounding boxes and masks for the image id\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "        # convert pixel values (e.g. center)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)\n",
    "        # extract results for first sample\n",
    "        r = yhat[0]\n",
    "        # calculate statistics, including AP\n",
    "        AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        # store\n",
    "        APs.append(AP)\n",
    "    # calculate the mean AP across all images\n",
    "    mAP = mean(APs)\n",
    "    return mAP\n",
    "\n",
    "# test set\n",
    "test_set = OurDataset()\n",
    "test_set.load_dataset(images_dir, ann_file, is_train=True, val_percentage = 0.0)\n",
    "test_set.prepare()\n",
    "print('Test images: %d' % len(test_set.image_ids))\n",
    "\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "\n",
    "# load model weights\n",
    "model.load_weights(net_weights_file, by_name=True)\n",
    "\n",
    "# evaluate model on test dataset\n",
    "train_mAP = evaluate_model(test_set, model, cfg)\n",
    "print(\"Train mAP: %.3f\" % train_mAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
